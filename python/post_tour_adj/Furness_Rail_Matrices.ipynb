{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis script builds on P:\\\\GBCBA\\\\HandT\\\\CQ\\\\Projects≈í7104-NorMITs Demand 2024-ADDY4067  Technical\\x02 TourModel\\\\Develop Tour Model\\\\Rail Coverage Analysis\\x01_processing\\\\ProcessMatrix\\\\JoinMatrixToGeography_v0.2.ipynb\\nIt is designed to ultimately obtain a furnessed version of the rail output matrix based on the rail ticketing data proportions\\nVersioning to be handled by Git (hopefully) once I've spoken to Rachel about where to put it\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script builds on P:\\GBCBA\\HandT\\CQ\\Projects\\5227104-NorMITs Demand 2024-ADDY4067\\40 Technical\\02 TourModel\\Develop Tour Model\\Rail Coverage Analysis\\01_processing\\ProcessMatrix\\JoinMatrixToGeography_v0.2.ipynb\n",
    "It is designed to ultimately obtain a furnessed version of the rail output matrix based on the rail ticketing data proportions\n",
    "Versioning to be handled by Git (hopefully) once I've spoken to Rachel about where to put it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# TfN packages\n",
    "# from caf.distribute import furness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "inputs_dir = r'P:\\GBCBA\\HandT\\CQ\\Projects\\5227104-NorMITs Demand 2024-ADDY4067\\40 Technical\\02 TourModel\\Develop Tour Model\\Rail Coverage Analysis\\00_inputs'\n",
    "gis_dir = r'P:\\GBCBA\\HandT\\CQ\\Projects\\5227104-NorMITs Demand 2024-ADDY4067\\40 Technical\\02 TourModel\\Develop Tour Model\\Rail Coverage Analysis\\01_processing\\GIS\\GISjoinOutput'\n",
    "\n",
    "# Set file names\n",
    "odm_file = 'ODM_for_rdm_2022-23.csv'\n",
    "msoa_county_file = 'msoa11cd_correspondence.csv'\n",
    "stn_geo_file = 'station_attributes_on_TfN_geography.csv'\n",
    "sector_file = 'bespoke_sectors_v1.1.csv'\n",
    "lrtu_file = 'lrt0101.csv'\n",
    "\n",
    "# Import data\n",
    "odm_in_df = pd.read_csv(os.path.join(inputs_dir, odm_file))\n",
    "msoa_county_in_df = pd.read_csv(os.path.join(inputs_dir, msoa_county_file))\n",
    "stn_geo_in_df = pd.read_csv(os.path.join(gis_dir, stn_geo_file))\n",
    "sector_in_df = pd.read_csv(os.path.join(inputs_dir, sector_file))\n",
    "lrtu_in_df = pd.read_csv(os.path.join(inputs_dir, lrtu_file), skiprows=7)\n",
    "lrtu_in_df.columns = lrtu_in_df.columns.str.split('[').str[0].str.strip() # Some processing required here to make column names tidier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other inputs\n",
    "Some manual inputs that set values later in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set light rail inputs\n",
    "lrtu_year_in = 2023 # Year for which to extract the Light Rail, Tramway and Underground data\n",
    "lrtu_london_scale_in = 0.25 # Proportion of trips on the London Underground, London Trams and Docklands Light Railway that are considered to be \"unique\" (i.e. not double counted with another rail mode)\n",
    "lrtu_nonlondon_scale_in = 0.5 # Proportion of trips on Light Rail, Tramway and Underground systems outside of London that are considered to be \"unique\" (i.e. not double counted with another rail mode)\n",
    "# For each Light Rail, Tramway or Underground system in GB, set the sector in which it is located. Done at sector level as some of these systems cross county borders\n",
    "lrtu_systems_in = {\n",
    "    'Docklands Light Railway': 'London',\n",
    "    'London Trams': 'London',\n",
    "    'Nottingham Express Transit': 'East Midlands North',\n",
    "    'West Midlands Metro': 'West Midlands South',\n",
    "    'Sheffield Supertram': 'South Yorkshire',\n",
    "    'Tyne and Wear Metro': 'Tyne and Wear',\n",
    "    'Manchester Metrolink': 'Greater Manchester',\n",
    "    'Blackpool Tramway': 'Lancashire',\n",
    "    'Edinburgh Trams': 'Scotland',\n",
    "    'London Underground': 'London',\n",
    "    'Glasgow Subway': 'Scotland'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to process rail ticketing/journey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lrtu_data(lrtu_df, lrtu_year, lrtu_systems, lrtu_london_scale, lrtu_nonlondon_scale):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    lrtu_df: pandas df\n",
    "        Light Rail, Tramway and Underground annual journey data by system as\n",
    "        read in by this script\n",
    "    lrtu_year\n",
    "    \"\"\"\n",
    "    # Process to account for odd formatting of source\n",
    "    lrtu_df = lrtu_df.dropna(axis=1, how='all')\n",
    "    lrtu_df = lrtu_df.dropna(axis=0, how='all')\n",
    "    lrtu_df = lrtu_df.rename(columns={'Financial year ending March': 'Year'})\n",
    "    lrtu_df['Year'] = lrtu_df['Year'].astype(int)\n",
    "\n",
    "    # Select data we are interested in and reformat to a system-based index\n",
    "    lrtu_df = lrtu_df.loc[lrtu_df['Year'] == lrtu_year]\n",
    "    lrtu_df = lrtu_df.set_index(['Year'])\n",
    "    lrtu_df = lrtu_df.transpose().reset_index()\n",
    "    lrtu_df = lrtu_df.rename_axis(None, axis=1)\n",
    "    lrtu_df = lrtu_df.rename(\n",
    "        columns={'index': 'System', lrtu_year: 'Yearly Journeys'})\n",
    "\n",
    "    # Convert yearly journeys to absolutes (and make sure they are numeric!)\n",
    "    # Note this bit will fall over if you pick a year before all systems\n",
    "    #   were returning data (i.e. some cells are '[w]')\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(str)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].str.replace(\n",
    "        ',', '')\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(float) * 10 # Just clear float to minimise rounding error risk\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(int)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'] * 100000 # Not 1 million as we've times by 10 about to get out of float\n",
    "\n",
    "    # Apply sectors to data\n",
    "    lrtu_df['Sector'] = lrtu_df['System'].map(lrtu_systems)\n",
    "    lrtu_df = lrtu_df.dropna(axis=0) # Drop rows where system name is not found (expected to be some total rows like all of GB)\n",
    "    if lrtu_df.shape[0] != len(lrtu_systems):\n",
    "        print('WARNING: The systems you have specified sectors for and the systems in the input file do not match!')\n",
    "    lrtu_df = lrtu_df.groupby(\n",
    "        ['Sector'])['Yearly Journeys'].sum().reset_index()\n",
    "\n",
    "    # Apply scaling factors to account for overlap with other rail modes (e.g. national rail, other light rail systems)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'] * np.where(\n",
    "        lrtu_df['Sector'] == 'London', lrtu_london_scale, lrtu_nonlondon_scale)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
