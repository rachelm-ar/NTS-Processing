{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis script builds on P:\\\\GBCBA\\\\HandT\\\\CQ\\\\ProjectsÅ’7104-NorMITs Demand 2024-ADDY4067  Technical\\x02 TourModel\\\\Develop Tour Model\\\\Rail Coverage Analysis\\x01_processing\\\\ProcessMatrix\\\\JoinMatrixToGeography_v0.2.ipynb\\nIt is designed to ultimately obtain a furnessed version of the rail output matrix based on the rail ticketing data proportions\\nVersioning to be handled by Git (hopefully) once I've spoken to Rachel about where to put it\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script builds on P:\\GBCBA\\HandT\\CQ\\Projects\\5227104-NorMITs Demand 2024-ADDY4067\\40 Technical\\02 TourModel\\Develop Tour Model\\Rail Coverage Analysis\\01_processing\\ProcessMatrix\\JoinMatrixToGeography_v0.2.ipynb\n",
    "It is designed to ultimately obtain a furnessed version of the rail output matrix based on the rail ticketing data proportions\n",
    "Versioning to be handled by Git (hopefully) once I've spoken to Rachel about where to put it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# TfN packages\n",
    "# import sys\n",
    "# # caution: path[0] is reserved for script path (or '' in REPL)\n",
    "# sys.path.insert(1, r'C:\\Users\\Jimny\\Documents\\GitHub\\caf.distribute\\src')\n",
    "\n",
    "# from caf.distribute import furness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Set directories\n",
    "inputs_dir = r'I:\\NTS\\imports\\tour_adjust_imports'\n",
    "msoa_dir = r'I:\\NTS\\imports'\n",
    "\n",
    "# Set file names\n",
    "odm_file = 'ODM_for_rdm_2022-23.csv'\n",
    "msoa_county_file = 'msoa11cd_correspondence.csv'\n",
    "stn_geo_file = 'station_attributes_on_TfN_geography.csv'\n",
    "sector_file = 'bespoke_sectors_v1.1.csv'\n",
    "lrtu_file = 'lrt0101.csv'\n",
    "\n",
    "# Import data\n",
    "odm_in_df = pd.read_csv(os.path.join(inputs_dir, odm_file))\n",
    "msoa_county_in_df = pd.read_csv(os.path.join(msoa_dir, msoa_county_file))\n",
    "stn_geo_in_df = pd.read_csv(os.path.join(inputs_dir, stn_geo_file))\n",
    "sector_in_df = pd.read_csv(os.path.join(inputs_dir, sector_file))\n",
    "lrtu_in_df = pd.read_csv(os.path.join(inputs_dir, lrtu_file), skiprows=7)\n",
    "lrtu_in_df.columns = lrtu_in_df.columns.str.split('[').str[0].str.strip() # Some processing required here to make column names tidier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other inputs\n",
    "Some manual inputs that set values later in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set light rail inputs\n",
    "lrtu_year_in = 2023 # Year for which to extract the Light Rail, Tramway and Underground data\n",
    "lrtu_london_scale_in = 0.25 # Proportion of trips on the London Underground, London Trams and Docklands Light Railway that are considered to be \"unique\" (i.e. not double counted with another rail mode)\n",
    "lrtu_nonlondon_scale_in = 0.5 # Proportion of trips on Light Rail, Tramway and Underground systems outside of London that are considered to be \"unique\" (i.e. not double counted with another rail mode)\n",
    "\n",
    "# For each Light Rail, Tramway or Underground system in GB,\n",
    "# set the sector in which it is located.\n",
    "# Done at sector level as some of these systems cross county borders\n",
    "lrtu_systems_in = {\n",
    "    'Docklands Light Railway': 'London',\n",
    "    'London Trams': 'London',\n",
    "    'Nottingham Express Transit': 'East Midlands North',\n",
    "    'West Midlands Metro': 'West Midlands South',\n",
    "    'Sheffield Supertram': 'South Yorkshire',\n",
    "    'Tyne and Wear Metro': 'Tyne and Wear',\n",
    "    'Manchester Metrolink': 'Greater Manchester',\n",
    "    'Blackpool Tramway': 'Lancashire',\n",
    "    'Edinburgh Trams': 'Scotland',\n",
    "    'London Underground': 'London',\n",
    "    'Glasgow Subway': 'Scotland'\n",
    "}\n",
    "\n",
    "# Set counties for stations that are located outside of the MSOA shapefile,\n",
    "# so get missed off the correspondence. This is a table here in case the station\n",
    "# shapefile is updated to add new stations\n",
    "\n",
    "# Need to account for:\n",
    "#  - Blackfriars (5112) - Bad join in the GIS as it's in the middle of the Thames!\n",
    "#  - Portsmouth Harbour (5540) - Bad join in the GIS as it's in the harbour...\n",
    "#  - Ryde Pier Head (5541) - Bad join as in the GIS as it is quite far out to sea!\n",
    "\n",
    "# Counties to allocate stations to:\n",
    "#  - Blackfriars -> Inner London (County 17)\n",
    "#  - Portsmouth Harbour -> Hampshire (County 35)\n",
    "#  - Ryde Pier Head -> Hampshire (County 35)\n",
    "\n",
    "stn_county_infill_df = pd.DataFrame(\n",
    "    columns=['National Location Code', 'county', 'county_nm'],\n",
    "    data=[[5112, 17, 'Inner London'],\n",
    "          [5540, 35, 'Hampshire'],\n",
    "          [5541, 35, 'Hampshire']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to process rail ticketing/journey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lrtu_data(lrtu_df, lrtu_year, lrtu_systems, lrtu_london_scale, lrtu_nonlondon_scale):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    lrtu_df: pandas df\n",
    "        Light Rail, Tramway and Underground annual journey data by system as\n",
    "        read in by this script\n",
    "    lrtu_year: int\n",
    "        Year for which to extract the Light Rail, Tramway and Underground data\n",
    "        It is the year in which the finacial year ends\n",
    "        It should match the year for which the national rail odm is downloaded\n",
    "    lrtu_systems: dict\n",
    "        Dictionary relating each Light Rail, Tramway or Underground system in\n",
    "        GB to the sector in which it is located\n",
    "    lrtu_london_scale: Float\n",
    "        Expected range 0.0 to 1.0\n",
    "        Proportion of trips on the London Underground, London Trams and\n",
    "        Docklands Light Railway that are considered to be \"unique\" (i.e. not\n",
    "        double counted with another rail mode)\n",
    "    lrtu_nonlondon_scale:\n",
    "        Expected range 0.0 to 1.0\n",
    "        Proportion of trips on Light Rail, Tramway and Underground systems\n",
    "        outside of London that are considered to be \"unique\" (i.e. not double\n",
    "        counted with another rail mode)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    lrtu_df: pandas df\n",
    "        For the selected year, the estimate of the number of \"unique\" (i.e. not\n",
    "        double counted with another rail mode) journeys by Light Rail, Tramway\n",
    "        and Underground for the sectors in which such systems are located.\n",
    "        This is an annual total\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic logic checks on inputs\n",
    "    yearnow = datetime.now().year\n",
    "    if not 2013 < lrtu_year <= yearnow or type(lrtu_year) not int:\n",
    "        print('WARNING: Unexpected input year for Light Rail, Tramway and Underground data')\n",
    "        print(f'Expected an interger year between 2014 and {yearnow}')\n",
    "        print(f'Instead, got {lrtu_year})\n",
    "    if not 0 < lrtu_london_scale <= 1:\n",
    "        print('WARNING: London scaling factor expected to be greater than 0, less the or equal to 1')\n",
    "        print(f'Instead got London scaling factor of {lrtu_london_scale}')\n",
    "    if not 0 < lrtu_nonlondon_scale <= 1:\n",
    "        print('WARNING: Outside London scaling factor expected to be greater than 0, less the or equal to 1')\n",
    "        print(f'Instead got outside London scaling factor of {lrtu_nonlondon_scale}')\n",
    "    \n",
    "    # Process to account for odd formatting of source\n",
    "    lrtu_df = lrtu_df.dropna(axis=1, how='all')\n",
    "    lrtu_df = lrtu_df.dropna(axis=0, how='all')\n",
    "    lrtu_df = lrtu_df.rename(columns={'Financial year ending March': 'Year'})\n",
    "    lrtu_df['Year'] = lrtu_df['Year'].astype(int)\n",
    "\n",
    "    # Select data we are interested in and reformat to a system-based index\n",
    "    lrtu_df = lrtu_df.loc[lrtu_df['Year'] == lrtu_year]\n",
    "    lrtu_df = lrtu_df.set_index(['Year'])\n",
    "    lrtu_df = lrtu_df.transpose().reset_index()\n",
    "    lrtu_df = lrtu_df.rename_axis(None, axis=1)\n",
    "    lrtu_df = lrtu_df.rename(\n",
    "        columns={'index': 'System', lrtu_year: 'Yearly Journeys'})\n",
    "\n",
    "    # Convert yearly journeys to absolutes (and make sure they are numeric!)\n",
    "    # Note this bit will fall over if you pick a year before all systems\n",
    "    #   were returning data (i.e. some cells are '[w]')\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(str)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].str.replace(\n",
    "        ',', '')\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(float) * 10 # Just clear float to minimise rounding error risk\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(int)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'] * 100000 # Not 1 million as we've times by 10 about to get out of float\n",
    "\n",
    "    # Apply sectors to data\n",
    "    lrtu_df['Sector'] = lrtu_df['System'].map(lrtu_systems)\n",
    "    lrtu_df = lrtu_df.dropna(axis=0) # Drop rows where system name is not found (expected to be some total rows like all of GB)\n",
    "    if lrtu_df.shape[0] != len(lrtu_systems):\n",
    "        print('WARNING: The systems you have specified sectors for and the systems in the input file do not match!')\n",
    "    lrtu_df = lrtu_df.groupby(\n",
    "        ['Sector'])['Yearly Journeys'].sum().reset_index()\n",
    "\n",
    "    # Apply scaling factors to account for overlap with other rail modes\n",
    "    # (e.g. national rail, other light rail systems)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'] * np.where(\n",
    "        lrtu_df['Sector'] == 'London', lrtu_london_scale, lrtu_nonlondon_scale)\n",
    "    lrtu_df['Yearly Journeys'] = lrtu_df['Yearly Journeys'].astype(int)\n",
    "    \n",
    "    return lrtu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_station_geography(odm_df, msoa_county_df, stn_geo_df, stn_infill_df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Cut down to just the columns of interest\n",
    "    # Note nlc (National Location Code) is a unique numerical code for each\n",
    "    # station\n",
    "    odm_df = odm_df[['origin_nlc',\n",
    "                     'origin_station_name',\n",
    "                     'destination_nlc',\n",
    "                     'destination_station_name',\n",
    "                     'journeys']]\n",
    "    msoa_county_df = msoa_county_df[['msoa11cd',\n",
    "                                     'county',\n",
    "                                     'county_nm']]\n",
    "    stn_geo_df = stn_geo_df[['National Location Code', 'msoa11cd']]\n",
    "    \n",
    "    # Assign counties to stations that are allocated MSOAs by the geospatial\n",
    "    # processing\n",
    "    stn_geo_df = stn_geo_df.merge(msoa_county_df, how='left', on='msoa11cd')\n",
    "    stn_geo_df = stn_geo_df.drop(columns=['msoa11cd'], axis=1)\n",
    "    \n",
    "    # Add on the stations that exist outside of the MSOA shapefile\n",
    "    # Drop rows containing nulls\n",
    "    if stn_geo_df[stn_geo_df.isnull().any(axis=1)].shape == stn_county_infill_df.shape:\n",
    "        # We are infilling something the same size as the NULL rows,\n",
    "        # which we want to do\n",
    "        # Drop the NULL rows, then append the replacements\n",
    "        stn_geo_df = stn_geo_df.dropna(how='any', axis=0)\n",
    "        stn_geo_df = pd.concat([stn_geo_df, stn_county_infill_df])\n",
    "        stn_geo_df.reset_index(inplace=True, drop=True)\n",
    "    else:\n",
    "        print('WARNING: The NULL infilling table you are trying to append is not the same dimensions as the NULL rows in the table')\n",
    "        print('Operation therefore not attempted and NULL rows are still in place')\n",
    "    \n",
    "    # Rename the National Location Code to make it a bit less unweildly\n",
    "    stn_geo_df = stn_geo_df.rename(columns={'National Location Code': 'nlc'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
